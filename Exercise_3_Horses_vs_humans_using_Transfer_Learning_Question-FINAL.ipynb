{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lbFmQdsZs5eW"
   },
   "outputs": [],
   "source": [
    "# ATTENTION: Please do not alter any of the provided code in the exercise. Only add your own code where indicated\n",
    "# ATTENTION: Please do not add or remove any cells in the exercise. The grader will check specific cells based on the cell position.\n",
    "# ATTENTION: Please use the provided epoch values when training.\n",
    "\n",
    "# Import all the necessary files!\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import Model\n",
    "from os import getcwd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1xJZ5glPPCRz"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tf-nightly\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/96/2b/f50487f165b56818c2c28c1117bd748ec5fc5906f099d304c987469af2bd/tf_nightly-2.4.0.dev20201012-cp36-cp36m-manylinux2010_x86_64.whl (392.2MB)\n",
      "\u001b[K     |████████████████████████████████| 392.2MB 57kB/s  eta 0:00:0111MB 13.6MB/s eta 0:00:27.1MB 86.3MB/s eta 0:00:04     |██████▌                         | 80.2MB 95.9MB/s eta 0:00:04    |████████████████                | 197.2MB 115.3MB/s eta 0:00:02  | 208.2MB 115.3MB/s eta 0:00:02��███████▉              | 219.1MB 115.3MB/s eta 0:00:02   | 241.3MB 115.3MB/s eta 0:00:02�████████▎           | 248.4MB 115.3MB/s eta 0:00:02��████████████████████▏          | 258.9MB 115.3MB/s eta 0:00:02     |██████████████████████▌         | 276.4MB 64.3MB/s eta 0:00:02:00:02��        | 294.2MB 64.3MB/s eta 0:00:02     |████████████████████████▌       | 300.7MB 64.3MB/s eta 0:00:02��████████████████▉       | 304.5MB 108.4MB/s eta 0:00:01 | 324.6MB 108.4MB/s eta 0:00:01��███▊    | 339.1MB 71.4MB/s eta 0:00:01     |████████████████████████████▋   | 351.1MB 71.4MB/s eta 0:00:01��██████████████████████████  | 368.1MB 71.4MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: numpy<1.19.0,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tf-nightly) (1.17.2)\n",
      "Collecting absl-py>=0.9.0 (from tf-nightly)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b9/07/f69dd3367368ad69f174bfe426a973651412ec11d48ec05c000f19fe0561/absl_py-0.10.0-py3-none-any.whl (127kB)\n",
      "\u001b[K     |████████████████████████████████| 133kB 39.1MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting astunparse==1.6.3 (from tf-nightly)\n",
      "  Downloading https://files.pythonhosted.org/packages/2b/03/13dde6512ad7b4557eb792fbcf0c653af6076b81e5941d36ec61f7ce6028/astunparse-1.6.3-py2.py3-none-any.whl\n",
      "Collecting tf-estimator-nightly (from tf-nightly)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1d/38/793490c571c0b95c8bf0965c428cf4032073d407822f8c82257471857410/tf_estimator_nightly-2.4.0.dev2020101301-py2.py3-none-any.whl (461kB)\n",
      "\u001b[K     |████████████████████████████████| 471kB 53.4MB/s eta 0:00:01�█████▊    | 399kB 53.4MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tf-nightly) (3.1.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tf-nightly) (1.1.0)\n",
      "Requirement already satisfied: wheel>=0.26 in /usr/lib/python3/dist-packages (from tf-nightly) (0.30.0)\n",
      "Collecting flatbuffers>=1.12 (from tf-nightly)\n",
      "  Downloading https://files.pythonhosted.org/packages/eb/26/712e578c5f14e26ae3314c39a1bdc4eb2ec2f4ddc89b708cf8e0a0d20423/flatbuffers-1.12-py2.py3-none-any.whl\n",
      "Collecting google-pasta>=0.1.8 (from tf-nightly)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a3/de/c648ef6835192e6e2cc03f40b19eeda4382c49b5bafb43d88b931c4c74ac/google_pasta-0.2.0-py3-none-any.whl (57kB)\n",
      "\u001b[K     |████████████████████████████████| 61kB 44.2MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tf-nightly) (1.24.0)\n",
      "Collecting keras-preprocessing<1.2,>=1.1.1 (from tf-nightly)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/79/4c/7c3275a01e12ef9368a892926ab932b33bb13d55794881e3573482b378a7/Keras_Preprocessing-1.1.2-py2.py3-none-any.whl (42kB)\n",
      "\u001b[K     |████████████████████████████████| 51kB 40.7MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.6/dist-packages (from tf-nightly) (3.9.2)\n",
      "Collecting typing-extensions>=3.7.4.2 (from tf-nightly)\n",
      "  Downloading https://files.pythonhosted.org/packages/60/7a/e881b5abb54db0e6e671ab088d079c57ce54e8a01a3ca443f561ccadb37e/typing_extensions-3.7.4.3-py3-none-any.whl\n",
      "Collecting gast==0.3.3 (from tf-nightly)\n",
      "  Downloading https://files.pythonhosted.org/packages/d6/84/759f5dd23fec8ba71952d97bcc7e2c9d7d63bdc582421f3cd4be845f0c98/gast-0.3.3-py2.py3-none-any.whl\n",
      "Collecting six>=1.12.0 (from tf-nightly)\n",
      "  Downloading https://files.pythonhosted.org/packages/ee/ff/48bde5c0f013094d729fe4b0316ba2a24774b3ff1c52d924a8a4cb04078a/six-1.15.0-py2.py3-none-any.whl\n",
      "Collecting portpicker>=1.3.0 (from tf-nightly)\n",
      "  Downloading https://files.pythonhosted.org/packages/d9/f4/0188bc07d38b5f9dd192b8329c5e098e3b23552c01a96fd08973dba9e315/portpicker-1.3.1.tar.gz\n",
      "Requirement already satisfied: h5py<2.11.0,>=2.10.0 in /usr/local/lib/python3.6/dist-packages (from tf-nightly) (2.10.0)\n",
      "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tf-nightly) (1.11.2)\n",
      "Collecting tb-nightly<3.0.0a0,>=2.4.0a0 (from tf-nightly)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/87/c0/85a249ff29ce96de70dce21e2118d293a7d0566a89f757e0726443b93a49/tb_nightly-2.4.0a20201012-py3-none-any.whl (10.6MB)\n",
      "\u001b[K     |████████████████████████████████| 10.6MB 37.7MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.9.2->tf-nightly) (41.2.0)\n",
      "Collecting tensorboard-plugin-wit>=1.6.0 (from tb-nightly<3.0.0a0,>=2.4.0a0->tf-nightly)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b6/85/5c5ac0a8c5efdfab916e9c6bc18963f6a6996a8a1e19ec4ad8c9ac9c623c/tensorboard_plugin_wit-1.7.0-py3-none-any.whl (779kB)\n",
      "\u001b[K     |████████████████████████████████| 788kB 65.0MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tb-nightly<3.0.0a0,>=2.4.0a0->tf-nightly) (3.1.1)\n",
      "Collecting google-auth-oauthlib<0.5,>=0.4.1 (from tb-nightly<3.0.0a0,>=2.4.0a0->tf-nightly)\n",
      "  Downloading https://files.pythonhosted.org/packages/7b/b8/88def36e74bee9fce511c9519571f4e485e890093ab7442284f4ffaef60b/google_auth_oauthlib-0.4.1-py2.py3-none-any.whl\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.6/dist-packages (from tb-nightly<3.0.0a0,>=2.4.0a0->tf-nightly) (2.22.0)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tb-nightly<3.0.0a0,>=2.4.0a0->tf-nightly) (0.16.0)\n",
      "Collecting google-auth<2,>=1.6.3 (from tb-nightly<3.0.0a0,>=2.4.0a0->tf-nightly)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1f/cf/724b6436967a8be879c8de16b09fd80e0e7b0bcad462f5c09ee021605785/google_auth-1.22.1-py2.py3-none-any.whl (114kB)\n",
      "\u001b[K     |████████████████████████████████| 122kB 1.8MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting requests-oauthlib>=0.7.0 (from google-auth-oauthlib<0.5,>=0.4.1->tb-nightly<3.0.0a0,>=2.4.0a0->tf-nightly)\n",
      "  Downloading https://files.pythonhosted.org/packages/a3/12/b92740d845ab62ea4edf04d2f4164d82532b5a0b03836d4d4e71c6f3d379/requests_oauthlib-1.3.0-py2.py3-none-any.whl\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tb-nightly<3.0.0a0,>=2.4.0a0->tf-nightly) (1.25.6)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tb-nightly<3.0.0a0,>=2.4.0a0->tf-nightly) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tb-nightly<3.0.0a0,>=2.4.0a0->tf-nightly) (2019.9.11)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /usr/lib/python3/dist-packages (from requests<3,>=2.21.0->tb-nightly<3.0.0a0,>=2.4.0a0->tf-nightly) (2.6)\n",
      "Collecting pyasn1-modules>=0.2.1 (from google-auth<2,>=1.6.3->tb-nightly<3.0.0a0,>=2.4.0a0->tf-nightly)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/95/de/214830a981892a3e286c3794f41ae67a4495df1108c3da8a9f62159b9a9d/pyasn1_modules-0.2.8-py2.py3-none-any.whl (155kB)\n",
      "\u001b[K     |████████████████████████████████| 163kB 75.5MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting rsa<5,>=3.1.4; python_version >= \"3.5\" (from google-auth<2,>=1.6.3->tb-nightly<3.0.0a0,>=2.4.0a0->tf-nightly)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1c/df/c3587a667d6b308fadc90b99e8bc8774788d033efcc70f4ecaae7fad144b/rsa-4.6-py3-none-any.whl (47kB)\n",
      "\u001b[K     |████████████████████████████████| 51kB 36.4MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting cachetools<5.0,>=2.0.0 (from google-auth<2,>=1.6.3->tb-nightly<3.0.0a0,>=2.4.0a0->tf-nightly)\n",
      "  Downloading https://files.pythonhosted.org/packages/cd/5c/f3aa86b6d5482f3051b433c7616668a9b96fbe49a622210e2c9781938a5c/cachetools-4.1.1-py3-none-any.whl\n",
      "Collecting oauthlib>=3.0.0 (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tb-nightly<3.0.0a0,>=2.4.0a0->tf-nightly)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/05/57/ce2e7a8fa7c0afb54a0581b14a65b56e62b5759dbc98e80627142b8a3704/oauthlib-3.1.0-py2.py3-none-any.whl (147kB)\n",
      "\u001b[K     |████████████████████████████████| 153kB 81.1MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting pyasn1<0.5.0,>=0.4.6 (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tb-nightly<3.0.0a0,>=2.4.0a0->tf-nightly)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/62/1e/a94a8d635fa3ce4cfc7f506003548d0a2447ae76fd5ca53932970fe3053f/pyasn1-0.4.8-py2.py3-none-any.whl (77kB)\n",
      "\u001b[K     |████████████████████████████████| 81kB 48.5MB/s eta 0:00:01\n",
      "\u001b[?25hBuilding wheels for collected packages: portpicker\n",
      "  Building wheel for portpicker (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for portpicker: filename=portpicker-1.3.1-cp36-none-any.whl size=10936 sha256=4fe7ad80368de5f02fbea2d945bddab6f578ece0594d445157096ae1510b3092\n",
      "  Stored in directory: /root/.cache/pip/wheels/ee/22/56/2f6e920030c7f82cc9f817a268443fab1a18fd6fe2be0ad232\n",
      "Successfully built portpicker\n",
      "\u001b[31mERROR: tensorflow-gpu 2.0.0 has requirement gast==0.2.2, but you'll have gast 0.3.3 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: tb-nightly 2.4.0a20201012 has requirement grpcio>=1.24.3, but you'll have grpcio 1.24.0 which is incompatible.\u001b[0m\n",
      "Installing collected packages: six, absl-py, astunparse, tf-estimator-nightly, flatbuffers, google-pasta, keras-preprocessing, typing-extensions, gast, portpicker, tensorboard-plugin-wit, pyasn1, pyasn1-modules, rsa, cachetools, google-auth, oauthlib, requests-oauthlib, google-auth-oauthlib, tb-nightly, tf-nightly\n",
      "  Found existing installation: six 1.11.0\n",
      "    Uninstalling six-1.11.0:\n",
      "      Successfully uninstalled six-1.11.0\n",
      "  Found existing installation: absl-py 0.8.0\n",
      "    Uninstalling absl-py-0.8.0:\n",
      "      Successfully uninstalled absl-py-0.8.0\n",
      "  Found existing installation: google-pasta 0.1.7\n",
      "    Uninstalling google-pasta-0.1.7:\n",
      "      Successfully uninstalled google-pasta-0.1.7\n",
      "  Found existing installation: Keras-Preprocessing 1.1.0\n",
      "    Uninstalling Keras-Preprocessing-1.1.0:\n",
      "      Successfully uninstalled Keras-Preprocessing-1.1.0\n",
      "  Found existing installation: gast 0.2.2\n",
      "    Uninstalling gast-0.2.2:\n",
      "      Successfully uninstalled gast-0.2.2\n",
      "Successfully installed absl-py-0.10.0 astunparse-1.6.3 cachetools-4.1.1 flatbuffers-1.12 gast-0.3.3 google-auth-1.22.1 google-auth-oauthlib-0.4.1 google-pasta-0.2.0 keras-preprocessing-1.1.2 oauthlib-3.1.0 portpicker-1.3.1 pyasn1-0.4.8 pyasn1-modules-0.2.8 requests-oauthlib-1.3.0 rsa-4.6 six-1.15.0 tb-nightly-2.4.0a20201012 tensorboard-plugin-wit-1.7.0 tf-estimator-nightly-2.4.0.dev2020101301 tf-nightly-2.4.0.dev20201012 typing-extensions-3.7.4.3\n",
      "\u001b[33mWARNING: You are using pip version 19.2.3, however version 20.2.3 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install tf-nightly\n",
    "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
    "\n",
    "local_weights_file = '/tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_trained_model = InceptionV3(input_shape = (150, 150, 3), include_top = False, weights = None)\n",
    "\n",
    "#pre_trained_model.load_weights('/tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5')\n",
    "\n",
    "#for layer in pre_trained_model.layers:layer.trainable = False\n",
    "# Expected Output is extremely large, but should end with:\n",
    "\n",
    "#Total params: 21,802,784\n",
    "#Trainable params: 0\n",
    "#Non-trainable params: 21,802,784"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CFsUlwdfs_wg"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "last layer output shape:  (None, 7, 7, 768)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "last_layer = pre_trained_model.get_layer('mixed7')\n",
    "print('last layer output shape: ', last_layer.output_shape)\n",
    "last_output = last_layer.output\n",
    "\n",
    "# Expected Output:\n",
    "# ('last layer output shape: ', (None, 7, 7, 768))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-bsWZWp5oMq9"
   },
   "outputs": [],
   "source": [
    "\n",
    "# Define a Callback class that stops training once accuracy reaches 99.9%\n",
    "class myCallback(tf.keras.callbacks.Callback):\n",
    "  def on_epoch_end(self, epoch, logs={}):\n",
    "    if(logs.get('acc')>0.999):\n",
    "      print(\"\\nReached 99.9% accuracy so cancelling training!\")\n",
    "      self.model.stop_training = True\n",
    "\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BMXb913pbvFg"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            [(None, 150, 150, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_94 (Conv2D)              (None, 74, 74, 32)   864         input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_94 (BatchNo (None, 74, 74, 32)   96          conv2d_94[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_94 (Activation)      (None, 74, 74, 32)   0           batch_normalization_94[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_95 (Conv2D)              (None, 72, 72, 32)   9216        activation_94[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_95 (BatchNo (None, 72, 72, 32)   96          conv2d_95[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_95 (Activation)      (None, 72, 72, 32)   0           batch_normalization_95[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_96 (Conv2D)              (None, 72, 72, 64)   18432       activation_95[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_96 (BatchNo (None, 72, 72, 64)   192         conv2d_96[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_96 (Activation)      (None, 72, 72, 64)   0           batch_normalization_96[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2D)  (None, 35, 35, 64)   0           activation_96[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_97 (Conv2D)              (None, 35, 35, 80)   5120        max_pooling2d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_97 (BatchNo (None, 35, 35, 80)   240         conv2d_97[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_97 (Activation)      (None, 35, 35, 80)   0           batch_normalization_97[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_98 (Conv2D)              (None, 33, 33, 192)  138240      activation_97[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_98 (BatchNo (None, 33, 33, 192)  576         conv2d_98[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_98 (Activation)      (None, 33, 33, 192)  0           batch_normalization_98[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2D)  (None, 16, 16, 192)  0           activation_98[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_102 (Conv2D)             (None, 16, 16, 64)   12288       max_pooling2d_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_102 (BatchN (None, 16, 16, 64)   192         conv2d_102[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_102 (Activation)     (None, 16, 16, 64)   0           batch_normalization_102[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_100 (Conv2D)             (None, 16, 16, 48)   9216        max_pooling2d_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_103 (Conv2D)             (None, 16, 16, 96)   55296       activation_102[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_100 (BatchN (None, 16, 16, 48)   144         conv2d_100[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_103 (BatchN (None, 16, 16, 96)   288         conv2d_103[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_100 (Activation)     (None, 16, 16, 48)   0           batch_normalization_100[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_103 (Activation)     (None, 16, 16, 96)   0           batch_normalization_103[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_9 (AveragePoo (None, 16, 16, 192)  0           max_pooling2d_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_99 (Conv2D)              (None, 16, 16, 64)   12288       max_pooling2d_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_101 (Conv2D)             (None, 16, 16, 64)   76800       activation_100[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_104 (Conv2D)             (None, 16, 16, 96)   82944       activation_103[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_105 (Conv2D)             (None, 16, 16, 32)   6144        average_pooling2d_9[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_99 (BatchNo (None, 16, 16, 64)   192         conv2d_99[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_101 (BatchN (None, 16, 16, 64)   192         conv2d_101[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_104 (BatchN (None, 16, 16, 96)   288         conv2d_104[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_105 (BatchN (None, 16, 16, 32)   96          conv2d_105[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_99 (Activation)      (None, 16, 16, 64)   0           batch_normalization_99[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_101 (Activation)     (None, 16, 16, 64)   0           batch_normalization_101[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_104 (Activation)     (None, 16, 16, 96)   0           batch_normalization_104[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_105 (Activation)     (None, 16, 16, 32)   0           batch_normalization_105[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed0 (Concatenate)            (None, 16, 16, 256)  0           activation_99[0][0]              \n",
      "                                                                 activation_101[0][0]             \n",
      "                                                                 activation_104[0][0]             \n",
      "                                                                 activation_105[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_109 (Conv2D)             (None, 16, 16, 64)   16384       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_109 (BatchN (None, 16, 16, 64)   192         conv2d_109[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_109 (Activation)     (None, 16, 16, 64)   0           batch_normalization_109[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_107 (Conv2D)             (None, 16, 16, 48)   12288       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_110 (Conv2D)             (None, 16, 16, 96)   55296       activation_109[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_107 (BatchN (None, 16, 16, 48)   144         conv2d_107[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_110 (BatchN (None, 16, 16, 96)   288         conv2d_110[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_107 (Activation)     (None, 16, 16, 48)   0           batch_normalization_107[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_110 (Activation)     (None, 16, 16, 96)   0           batch_normalization_110[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_10 (AveragePo (None, 16, 16, 256)  0           mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_106 (Conv2D)             (None, 16, 16, 64)   16384       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_108 (Conv2D)             (None, 16, 16, 64)   76800       activation_107[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_111 (Conv2D)             (None, 16, 16, 96)   82944       activation_110[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_112 (Conv2D)             (None, 16, 16, 64)   16384       average_pooling2d_10[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_106 (BatchN (None, 16, 16, 64)   192         conv2d_106[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_108 (BatchN (None, 16, 16, 64)   192         conv2d_108[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_111 (BatchN (None, 16, 16, 96)   288         conv2d_111[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_112 (BatchN (None, 16, 16, 64)   192         conv2d_112[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_106 (Activation)     (None, 16, 16, 64)   0           batch_normalization_106[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_108 (Activation)     (None, 16, 16, 64)   0           batch_normalization_108[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_111 (Activation)     (None, 16, 16, 96)   0           batch_normalization_111[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_112 (Activation)     (None, 16, 16, 64)   0           batch_normalization_112[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed1 (Concatenate)            (None, 16, 16, 288)  0           activation_106[0][0]             \n",
      "                                                                 activation_108[0][0]             \n",
      "                                                                 activation_111[0][0]             \n",
      "                                                                 activation_112[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_116 (Conv2D)             (None, 16, 16, 64)   18432       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_116 (BatchN (None, 16, 16, 64)   192         conv2d_116[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_116 (Activation)     (None, 16, 16, 64)   0           batch_normalization_116[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_114 (Conv2D)             (None, 16, 16, 48)   13824       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_117 (Conv2D)             (None, 16, 16, 96)   55296       activation_116[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_114 (BatchN (None, 16, 16, 48)   144         conv2d_114[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_117 (BatchN (None, 16, 16, 96)   288         conv2d_117[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_114 (Activation)     (None, 16, 16, 48)   0           batch_normalization_114[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_117 (Activation)     (None, 16, 16, 96)   0           batch_normalization_117[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_11 (AveragePo (None, 16, 16, 288)  0           mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_113 (Conv2D)             (None, 16, 16, 64)   18432       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_115 (Conv2D)             (None, 16, 16, 64)   76800       activation_114[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_118 (Conv2D)             (None, 16, 16, 96)   82944       activation_117[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_119 (Conv2D)             (None, 16, 16, 64)   18432       average_pooling2d_11[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_113 (BatchN (None, 16, 16, 64)   192         conv2d_113[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_115 (BatchN (None, 16, 16, 64)   192         conv2d_115[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_118 (BatchN (None, 16, 16, 96)   288         conv2d_118[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_119 (BatchN (None, 16, 16, 64)   192         conv2d_119[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_113 (Activation)     (None, 16, 16, 64)   0           batch_normalization_113[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_115 (Activation)     (None, 16, 16, 64)   0           batch_normalization_115[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_118 (Activation)     (None, 16, 16, 96)   0           batch_normalization_118[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_119 (Activation)     (None, 16, 16, 64)   0           batch_normalization_119[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed2 (Concatenate)            (None, 16, 16, 288)  0           activation_113[0][0]             \n",
      "                                                                 activation_115[0][0]             \n",
      "                                                                 activation_118[0][0]             \n",
      "                                                                 activation_119[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_121 (Conv2D)             (None, 16, 16, 64)   18432       mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_121 (BatchN (None, 16, 16, 64)   192         conv2d_121[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_121 (Activation)     (None, 16, 16, 64)   0           batch_normalization_121[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_122 (Conv2D)             (None, 16, 16, 96)   55296       activation_121[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_122 (BatchN (None, 16, 16, 96)   288         conv2d_122[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_122 (Activation)     (None, 16, 16, 96)   0           batch_normalization_122[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_120 (Conv2D)             (None, 7, 7, 384)    995328      mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_123 (Conv2D)             (None, 7, 7, 96)     82944       activation_122[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_120 (BatchN (None, 7, 7, 384)    1152        conv2d_120[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_123 (BatchN (None, 7, 7, 96)     288         conv2d_123[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_120 (Activation)     (None, 7, 7, 384)    0           batch_normalization_120[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_123 (Activation)     (None, 7, 7, 96)     0           batch_normalization_123[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2D)  (None, 7, 7, 288)    0           mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "mixed3 (Concatenate)            (None, 7, 7, 768)    0           activation_120[0][0]             \n",
      "                                                                 activation_123[0][0]             \n",
      "                                                                 max_pooling2d_6[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_128 (Conv2D)             (None, 7, 7, 128)    98304       mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_128 (BatchN (None, 7, 7, 128)    384         conv2d_128[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_128 (Activation)     (None, 7, 7, 128)    0           batch_normalization_128[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_129 (Conv2D)             (None, 7, 7, 128)    114688      activation_128[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_129 (BatchN (None, 7, 7, 128)    384         conv2d_129[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_129 (Activation)     (None, 7, 7, 128)    0           batch_normalization_129[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_125 (Conv2D)             (None, 7, 7, 128)    98304       mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_130 (Conv2D)             (None, 7, 7, 128)    114688      activation_129[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_125 (BatchN (None, 7, 7, 128)    384         conv2d_125[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_130 (BatchN (None, 7, 7, 128)    384         conv2d_130[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_125 (Activation)     (None, 7, 7, 128)    0           batch_normalization_125[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_130 (Activation)     (None, 7, 7, 128)    0           batch_normalization_130[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_126 (Conv2D)             (None, 7, 7, 128)    114688      activation_125[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_131 (Conv2D)             (None, 7, 7, 128)    114688      activation_130[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_126 (BatchN (None, 7, 7, 128)    384         conv2d_126[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_131 (BatchN (None, 7, 7, 128)    384         conv2d_131[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_126 (Activation)     (None, 7, 7, 128)    0           batch_normalization_126[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_131 (Activation)     (None, 7, 7, 128)    0           batch_normalization_131[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_12 (AveragePo (None, 7, 7, 768)    0           mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_124 (Conv2D)             (None, 7, 7, 192)    147456      mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_127 (Conv2D)             (None, 7, 7, 192)    172032      activation_126[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_132 (Conv2D)             (None, 7, 7, 192)    172032      activation_131[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_133 (Conv2D)             (None, 7, 7, 192)    147456      average_pooling2d_12[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_124 (BatchN (None, 7, 7, 192)    576         conv2d_124[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_127 (BatchN (None, 7, 7, 192)    576         conv2d_127[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_132 (BatchN (None, 7, 7, 192)    576         conv2d_132[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_133 (BatchN (None, 7, 7, 192)    576         conv2d_133[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_124 (Activation)     (None, 7, 7, 192)    0           batch_normalization_124[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_127 (Activation)     (None, 7, 7, 192)    0           batch_normalization_127[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_132 (Activation)     (None, 7, 7, 192)    0           batch_normalization_132[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_133 (Activation)     (None, 7, 7, 192)    0           batch_normalization_133[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed4 (Concatenate)            (None, 7, 7, 768)    0           activation_124[0][0]             \n",
      "                                                                 activation_127[0][0]             \n",
      "                                                                 activation_132[0][0]             \n",
      "                                                                 activation_133[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_138 (Conv2D)             (None, 7, 7, 160)    122880      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_138 (BatchN (None, 7, 7, 160)    480         conv2d_138[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_138 (Activation)     (None, 7, 7, 160)    0           batch_normalization_138[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_139 (Conv2D)             (None, 7, 7, 160)    179200      activation_138[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_139 (BatchN (None, 7, 7, 160)    480         conv2d_139[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_139 (Activation)     (None, 7, 7, 160)    0           batch_normalization_139[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_135 (Conv2D)             (None, 7, 7, 160)    122880      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_140 (Conv2D)             (None, 7, 7, 160)    179200      activation_139[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_135 (BatchN (None, 7, 7, 160)    480         conv2d_135[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_140 (BatchN (None, 7, 7, 160)    480         conv2d_140[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_135 (Activation)     (None, 7, 7, 160)    0           batch_normalization_135[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_140 (Activation)     (None, 7, 7, 160)    0           batch_normalization_140[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_136 (Conv2D)             (None, 7, 7, 160)    179200      activation_135[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_141 (Conv2D)             (None, 7, 7, 160)    179200      activation_140[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_136 (BatchN (None, 7, 7, 160)    480         conv2d_136[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_141 (BatchN (None, 7, 7, 160)    480         conv2d_141[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_136 (Activation)     (None, 7, 7, 160)    0           batch_normalization_136[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_141 (Activation)     (None, 7, 7, 160)    0           batch_normalization_141[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_13 (AveragePo (None, 7, 7, 768)    0           mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_134 (Conv2D)             (None, 7, 7, 192)    147456      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_137 (Conv2D)             (None, 7, 7, 192)    215040      activation_136[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_142 (Conv2D)             (None, 7, 7, 192)    215040      activation_141[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_143 (Conv2D)             (None, 7, 7, 192)    147456      average_pooling2d_13[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_134 (BatchN (None, 7, 7, 192)    576         conv2d_134[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_137 (BatchN (None, 7, 7, 192)    576         conv2d_137[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_142 (BatchN (None, 7, 7, 192)    576         conv2d_142[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_143 (BatchN (None, 7, 7, 192)    576         conv2d_143[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_134 (Activation)     (None, 7, 7, 192)    0           batch_normalization_134[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_137 (Activation)     (None, 7, 7, 192)    0           batch_normalization_137[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_142 (Activation)     (None, 7, 7, 192)    0           batch_normalization_142[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_143 (Activation)     (None, 7, 7, 192)    0           batch_normalization_143[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed5 (Concatenate)            (None, 7, 7, 768)    0           activation_134[0][0]             \n",
      "                                                                 activation_137[0][0]             \n",
      "                                                                 activation_142[0][0]             \n",
      "                                                                 activation_143[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_148 (Conv2D)             (None, 7, 7, 160)    122880      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_148 (BatchN (None, 7, 7, 160)    480         conv2d_148[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_148 (Activation)     (None, 7, 7, 160)    0           batch_normalization_148[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_149 (Conv2D)             (None, 7, 7, 160)    179200      activation_148[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_149 (BatchN (None, 7, 7, 160)    480         conv2d_149[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_149 (Activation)     (None, 7, 7, 160)    0           batch_normalization_149[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_145 (Conv2D)             (None, 7, 7, 160)    122880      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_150 (Conv2D)             (None, 7, 7, 160)    179200      activation_149[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_145 (BatchN (None, 7, 7, 160)    480         conv2d_145[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_150 (BatchN (None, 7, 7, 160)    480         conv2d_150[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_145 (Activation)     (None, 7, 7, 160)    0           batch_normalization_145[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_150 (Activation)     (None, 7, 7, 160)    0           batch_normalization_150[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_146 (Conv2D)             (None, 7, 7, 160)    179200      activation_145[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_151 (Conv2D)             (None, 7, 7, 160)    179200      activation_150[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_146 (BatchN (None, 7, 7, 160)    480         conv2d_146[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_151 (BatchN (None, 7, 7, 160)    480         conv2d_151[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_146 (Activation)     (None, 7, 7, 160)    0           batch_normalization_146[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_151 (Activation)     (None, 7, 7, 160)    0           batch_normalization_151[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_14 (AveragePo (None, 7, 7, 768)    0           mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_144 (Conv2D)             (None, 7, 7, 192)    147456      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_147 (Conv2D)             (None, 7, 7, 192)    215040      activation_146[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_152 (Conv2D)             (None, 7, 7, 192)    215040      activation_151[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_153 (Conv2D)             (None, 7, 7, 192)    147456      average_pooling2d_14[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_144 (BatchN (None, 7, 7, 192)    576         conv2d_144[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_147 (BatchN (None, 7, 7, 192)    576         conv2d_147[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_152 (BatchN (None, 7, 7, 192)    576         conv2d_152[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_153 (BatchN (None, 7, 7, 192)    576         conv2d_153[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_144 (Activation)     (None, 7, 7, 192)    0           batch_normalization_144[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_147 (Activation)     (None, 7, 7, 192)    0           batch_normalization_147[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_152 (Activation)     (None, 7, 7, 192)    0           batch_normalization_152[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_153 (Activation)     (None, 7, 7, 192)    0           batch_normalization_153[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed6 (Concatenate)            (None, 7, 7, 768)    0           activation_144[0][0]             \n",
      "                                                                 activation_147[0][0]             \n",
      "                                                                 activation_152[0][0]             \n",
      "                                                                 activation_153[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_158 (Conv2D)             (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_158 (BatchN (None, 7, 7, 192)    576         conv2d_158[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_158 (Activation)     (None, 7, 7, 192)    0           batch_normalization_158[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_159 (Conv2D)             (None, 7, 7, 192)    258048      activation_158[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_159 (BatchN (None, 7, 7, 192)    576         conv2d_159[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_159 (Activation)     (None, 7, 7, 192)    0           batch_normalization_159[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_155 (Conv2D)             (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_160 (Conv2D)             (None, 7, 7, 192)    258048      activation_159[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_155 (BatchN (None, 7, 7, 192)    576         conv2d_155[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_160 (BatchN (None, 7, 7, 192)    576         conv2d_160[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_155 (Activation)     (None, 7, 7, 192)    0           batch_normalization_155[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_160 (Activation)     (None, 7, 7, 192)    0           batch_normalization_160[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_156 (Conv2D)             (None, 7, 7, 192)    258048      activation_155[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_161 (Conv2D)             (None, 7, 7, 192)    258048      activation_160[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_156 (BatchN (None, 7, 7, 192)    576         conv2d_156[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_161 (BatchN (None, 7, 7, 192)    576         conv2d_161[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_156 (Activation)     (None, 7, 7, 192)    0           batch_normalization_156[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_161 (Activation)     (None, 7, 7, 192)    0           batch_normalization_161[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_15 (AveragePo (None, 7, 7, 768)    0           mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_154 (Conv2D)             (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_157 (Conv2D)             (None, 7, 7, 192)    258048      activation_156[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_162 (Conv2D)             (None, 7, 7, 192)    258048      activation_161[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_163 (Conv2D)             (None, 7, 7, 192)    147456      average_pooling2d_15[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_154 (BatchN (None, 7, 7, 192)    576         conv2d_154[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_157 (BatchN (None, 7, 7, 192)    576         conv2d_157[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_162 (BatchN (None, 7, 7, 192)    576         conv2d_162[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_163 (BatchN (None, 7, 7, 192)    576         conv2d_163[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_154 (Activation)     (None, 7, 7, 192)    0           batch_normalization_154[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_157 (Activation)     (None, 7, 7, 192)    0           batch_normalization_157[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_162 (Activation)     (None, 7, 7, 192)    0           batch_normalization_162[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_163 (Activation)     (None, 7, 7, 192)    0           batch_normalization_163[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed7 (Concatenate)            (None, 7, 7, 768)    0           activation_154[0][0]             \n",
      "                                                                 activation_157[0][0]             \n",
      "                                                                 activation_162[0][0]             \n",
      "                                                                 activation_163[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 37632)        0           mixed7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 1024)         38536192    flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 1024)         0           dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 1)            1025        dropout[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 47,512,481\n",
      "Trainable params: 47,493,665\n",
      "Non-trainable params: 18,816\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.optimizers import RMSprop\n",
    "\n",
    "# Flatten the output layer to 1 dimension\n",
    "x = layers.Flatten()(last_output)\n",
    "# Add a fully connected layer with 1,024 hidden units and ReLU activation\n",
    "x = layers.Dense(1024, activation='relu')(x)\n",
    "# Add a dropout rate of 0.2\n",
    "x = layers.Dropout(.2)(x)                  \n",
    "# Add a final sigmoid layer for classification\n",
    "x = layers.Dense(1, activation='sigmoid')(x)           \n",
    "\n",
    "model = Model(pre_trained_model.input, x) \n",
    "\n",
    "model.compile(\n",
    "    optimizer=RMSprop(lr=0.0001), \n",
    "    loss='binary_crossentropy', \n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "model.summary()\n",
    "\n",
    "# Expected output will be large. Last few lines should be:\n",
    "\n",
    "# mixed7 (Concatenate)            (None, 7, 7, 768)    0           activation_248[0][0]             \n",
    "#                                                                  activation_251[0][0]             \n",
    "#                                                                  activation_256[0][0]             \n",
    "#                                                                  activation_257[0][0]             \n",
    "# __________________________________________________________________________________________________\n",
    "# flatten_4 (Flatten)             (None, 37632)        0           mixed7[0][0]                     \n",
    "# __________________________________________________________________________________________________\n",
    "# dense_8 (Dense)                 (None, 1024)         38536192    flatten_4[0][0]                  \n",
    "# __________________________________________________________________________________________________\n",
    "# dropout_4 (Dropout)             (None, 1024)         0           dense_8[0][0]                    \n",
    "# __________________________________________________________________________________________________\n",
    "# dense_9 (Dense)                 (None, 1)            1025        dropout_4[0][0]                  \n",
    "# ==================================================================================================\n",
    "# Total params: 47,512,481\n",
    "# Trainable params: 38,537,217\n",
    "# Non-trainable params: 8,975,264\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HrnL_IQ8knWA"
   },
   "outputs": [],
   "source": [
    "# Get the Horse or Human dataset\n",
    "path_horse_or_human = f\"{getcwd()}/../tmp2/horse-or-human.zip\"\n",
    "# Get the Horse or Human Validation dataset\n",
    "path_validation_horse_or_human = f\"{getcwd()}/../tmp2/validation-horse-or-human.zip\"\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "import os\n",
    "import zipfile\n",
    "import shutil\n",
    "\n",
    "shutil.rmtree('/tmp')\n",
    "local_zip = path_horse_or_human\n",
    "zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
    "zip_ref.extractall('/tmp/training')\n",
    "zip_ref.close()\n",
    "\n",
    "local_zip = path_validation_horse_or_human\n",
    "zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
    "zip_ref.extractall('/tmp/validation')\n",
    "zip_ref.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "y9okX7_ovskI"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500\n",
      "527\n",
      "128\n",
      "128\n"
     ]
    }
   ],
   "source": [
    "# Define our example directories and files\n",
    "train_dir = '/tmp/training'\n",
    "validation_dir = '/tmp/validation'\n",
    "\n",
    "train_horses_dir = os.path.join(train_dir, 'horses') \n",
    "train_humans_dir = os.path.join(train_dir, 'humans') \n",
    "validation_horses_dir = os.path.join(validation_dir, 'horses')\n",
    "validation_humans_dir = os.path.join(validation_dir, 'humans')\n",
    "\n",
    "train_horses_fnames = os.listdir(train_horses_dir)\n",
    "train_humans_fnames = os.listdir(train_humans_dir)\n",
    "validation_horses_fnames = os.listdir(validation_horses_dir)\n",
    "validation_humans_fnames = os.listdir(validation_humans_dir)\n",
    "\n",
    "print(len(train_horses_fnames))\n",
    "print(len(train_humans_fnames))\n",
    "print(len(validation_horses_fnames))\n",
    "print(len(validation_humans_fnames))\n",
    "\n",
    "# Expected Output:\n",
    "# 500\n",
    "# 527\n",
    "# 128\n",
    "# 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "O4s8HckqGlnb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1027 images belonging to 2 classes.\n",
      "Found 256 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Add our data-augmentation parameters to ImageDataGenerator\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale = 1./255.,\n",
    "    rotation_range = 40,\n",
    "    width_shift_range = 0.2,\n",
    "    height_shift_range = 0.2,\n",
    "    shear_range = 0.2,\n",
    "    zoom_range = 0.2,\n",
    "    horizontal_flip = True\n",
    ")\n",
    "\n",
    "# Note that the validation data should not be augmented!\n",
    "test_datagen = ImageDataGenerator(\n",
    "    rescale = 1./255.\n",
    ")\n",
    "\n",
    "# Flow training images in batches of 20 using train_datagen generator\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    batch_size=10,\n",
    "    class_mode='binary',\n",
    "    target_size=(150,150)\n",
    ")     \n",
    "\n",
    "# Flow validation images in batches of 20 using test_datagen generator\n",
    "validation_generator =  test_datagen.flow_from_directory(\n",
    "    validation_dir,\n",
    "    batch_size=10,\n",
    "    class_mode='binary',\n",
    "    target_size=(150,150)\n",
    ")\n",
    "\n",
    "# Expected Output:\n",
    "# Found 1027 images belonging to 2 classes.\n",
    "# Found 256 images belonging to 2 classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Blhq2MAUeyGA"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "25/25 - 33s - loss: 6.9678 - accuracy: 0.5240 - val_loss: 2.2977 - val_accuracy: 0.5080\n",
      "Epoch 2/15\n",
      "25/25 - 26s - loss: 7.7893 - accuracy: 0.4920 - val_loss: 4.4343 - val_accuracy: 0.5080\n",
      "Epoch 3/15\n",
      "25/25 - 26s - loss: 7.5440 - accuracy: 0.5080 - val_loss: 6.3899 - val_accuracy: 0.5080\n",
      "Epoch 4/15\n",
      "25/25 - 24s - loss: 7.5619 - accuracy: 0.5061 - val_loss: 7.5440 - val_accuracy: 0.5080\n",
      "Epoch 5/15\n",
      "25/25 - 29s - loss: 6.3173 - accuracy: 0.5880 - val_loss: 7.5440 - val_accuracy: 0.5080\n",
      "Epoch 6/15\n",
      "25/25 - 29s - loss: 7.6053 - accuracy: 0.5040 - val_loss: 7.5440 - val_accuracy: 0.5080\n",
      "Epoch 7/15\n",
      "25/25 - 29s - loss: 7.8687 - accuracy: 0.4858 - val_loss: 7.5440 - val_accuracy: 0.5080\n",
      "Epoch 8/15\n",
      "25/25 - 26s - loss: 7.4213 - accuracy: 0.5160 - val_loss: 7.5440 - val_accuracy: 0.5080\n",
      "Epoch 9/15\n",
      "25/25 - 28s - loss: 8.1573 - accuracy: 0.4680 - val_loss: 7.5440 - val_accuracy: 0.5080\n",
      "Epoch 10/15\n",
      "25/25 - 26s - loss: 7.7893 - accuracy: 0.4920 - val_loss: 7.5440 - val_accuracy: 0.5080\n",
      "Epoch 11/15\n",
      "25/25 - 26s - loss: 7.9120 - accuracy: 0.4840 - val_loss: 7.5440 - val_accuracy: 0.5080\n",
      "Epoch 12/15\n",
      "25/25 - 25s - loss: 6.4574 - accuracy: 0.5789 - val_loss: 7.5440 - val_accuracy: 0.5080\n",
      "Epoch 13/15\n",
      "25/25 - 25s - loss: 8.2186 - accuracy: 0.4640 - val_loss: 7.5440 - val_accuracy: 0.5080\n",
      "Epoch 14/15\n",
      "25/25 - 26s - loss: 7.5440 - accuracy: 0.5080 - val_loss: 7.5440 - val_accuracy: 0.5080\n",
      "Epoch 15/15\n",
      "25/25 - 27s - loss: 6.8978 - accuracy: 0.5466 - val_loss: 7.5440 - val_accuracy: 0.5080\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Run this and see how many epochs it should take before the callback\n",
    "# fires, and stops training at 99.9% accuracy\n",
    "# (It should take less than 100 epochs)\n",
    "\n",
    "history = model.fit_generator(\n",
    "            train_generator,\n",
    "            validation_data = validation_generator,\n",
    "            steps_per_epoch = 25,\n",
    "            epochs = 15,\n",
    "            validation_steps = 25,\n",
    "            verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "C2Fp6Se9rKuL"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(len(acc))\n",
    "\n",
    "plt.plot(epochs, acc, 'r', label='Training accuracy')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation accuracy')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.legend(loc=0)\n",
    "plt.figure()\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submission Instructions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now click the 'Submit Assignment' button above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# When you're done or would like to take a break, please run the two cells below to save your work and close the Notebook. This will free up resources for your fellow learners. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%javascript\n",
    "<!-- Save the notebook -->\n",
    "IPython.notebook.save_checkpoint();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%javascript\n",
    "IPython.notebook.session.delete();\n",
    "window.onbeforeunload = null\n",
    "setTimeout(function() { window.close(); }, 1000);"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Exercise 7 - Question.ipynb",
   "provenance": []
  },
  "coursera": {
   "course_slug": "convolutional-neural-networks-tensorflow",
   "graded_item_id": "csg1x",
   "launcher_item_id": "GpKYz"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
